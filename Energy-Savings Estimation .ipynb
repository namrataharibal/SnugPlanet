{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pytz \n",
    "import eemeter \n",
    "import glob\n",
    "import re\n",
    "import requests \n",
    "import json \n",
    "from os import getcwd, path \n",
    "\n",
    "# Packages to connect to Google Sheets \n",
    "import pickle \n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectEvaluator: \n",
    "    def __init__(self, \n",
    "                 bill, \n",
    "                 update_temp_data=False, \n",
    "                 update_metadata=False):\n",
    "        \n",
    "        self.meter_data = pd.read_csv(bill)\n",
    "        \n",
    "        self.temperature_data = pd.read_csv(\"temperature_data.csv\")\n",
    "        self.temperature_data = self.temperature_data[[\"time\", \"temperature (F)\"]]\n",
    "        self.temperature_data[\"time\"] = pd.to_datetime(self.temperature_data[\"time\"])\n",
    "        \n",
    "        \n",
    "        self.metadata = pd.read_csv(\"Metadata.csv\")\n",
    "        \n",
    "        self.pod_id = re.findall('(?<=\\/)(.*?)(?=\\.)', bill)[0]\n",
    "        self.bill_type = re.findall('.*(?=/)', bill)[0]\n",
    "        \n",
    "        temp = self.metadata[self.metadata[\"{}_PoD_ID\".format(self.bill_type)] == self.pod_id]\n",
    "        key =  temp[\"Project_Start_Date\"].index.tolist()[0]\n",
    "        \n",
    "        self.project_start_date = pd.to_datetime(self.metadata[\"Project_Start_Date\"][self.metadata[\"{}_PoD_ID\".format(self.bill_type)] == self.pod_id][key])\n",
    "        self.project_end_date = pd.to_datetime(self.metadata[\"Project_Completition_Date\"][self.metadata[\"{}_PoD_ID\".format(self.bill_type)] == self.pod_id][key])\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.meter_data = self.meter_data.iloc[::-1]\n",
    "        self.meter_data[\"start\"] = pd.to_datetime(self.meter_data[\"start\"])\n",
    "        meter_filter = (self.meter_data[\"start\"] >= self.temperature_data.iloc[0][\"time\"])\n",
    "        self.meter_data = self.meter_data.loc[meter_filter]\n",
    "        self.meter_data = self.meter_data[[\"start\", \"value\"]]\n",
    "        \n",
    "        \n",
    "    def create_baseline_data(self): \n",
    "        '''\n",
    "        This method consolidates all the necessary meter and temperature data \n",
    "        necessary to create the design matrix and baseline model to create the predictions. \n",
    "        the baseline meter data from the complete \n",
    "        SKIP if baseline meter data already exists. \n",
    "    \n",
    "        '''        \n",
    "        \n",
    "        baseline_meter_filter = (self.meter_data[\"start\"] <= self.project_start_date)\n",
    "        self.baseline_meter_data = self.meter_data[baseline_meter_filter]        \n",
    "        \n",
    "        baseline_start = self.baseline_meter_data[\"start\"].iloc[0].date()\n",
    "        baseline_end = self.baseline_meter_data[\"start\"].iloc[-1].date() + pd.offsets.Day(1)\n",
    "        \n",
    "        \n",
    "        baseline_temp_mask = (self.temperature_data[\"time\"] >= baseline_start) & (self.temperature_data[\"time\"] <= baseline_end)\n",
    "        self.baseline_temp_data = self.temperature_data.loc[baseline_temp_mask]\n",
    "        self.baseline_temp_data = self.baseline_temp_data.rename(columns={\"time\": \"dt\",\n",
    "                                                                          \"temperature (F)\": \"tempF\"})\n",
    "        \n",
    "        self.baseline_meter_data = self.baseline_meter_data.set_index(\"start\")\n",
    "        self.baseline_temp_data = self.baseline_temp_data.set_index(\"dt\")\n",
    "        \n",
    "        baseline_meter_path = getcwd() + \"/{}_\".format(self.pod_id ) + \"baseline_meter\" \n",
    "        baseline_temp_path = getcwd() + \"/{}_\".format(self.pod_id ) + \"baseline_temp\" \n",
    "        \n",
    "        self.baseline_meter_data = self.baseline_meter_data.to_csv(r'{}'.format(baseline_meter_path))\n",
    "        self.baseline_temp_data = self.baseline_temp_data.to_csv(r'{}'.format(baseline_temp_path))\n",
    "        \n",
    "        self.ee_baseline_meter = eemeter.meter_data_from_csv(baseline_meter_path)\n",
    "        \n",
    "        self.ee_baseline_temp = eemeter.temperature_data_from_csv(baseline_temp_path) \n",
    "        self.ee_baseline_temp = self.ee_baseline_temp.asfreq('H')\n",
    "        \n",
    "                \n",
    "        return self.ee_baseline_meter, self.ee_baseline_temp \n",
    "\n",
    "    \n",
    "    def create_prediction_data(self): \n",
    "        '''\n",
    "        '''\n",
    "        prediction_meter_filter = (self.meter_data[\"start\"] > self.project_end_date)\n",
    "        self.prediction_meter_data = self.meter_data[prediction_meter_filter]\n",
    "        \n",
    "        self.prediction_start = self.project_end_date + pd.offsets.Day(1)\n",
    "        self.prediction_end  = self.meter_data[\"start\"].iloc[-1].date() + pd.offsets.Day(1)\n",
    "        \n",
    "        prediction_temp_filter = (self.temperature_data[\"time\"] >= self.prediction_start) & (self.temperature_data[\"time\"] <= self.prediction_end)\n",
    "        self.prediction_temp_data = self.temperature_data.loc[prediction_temp_filter]\n",
    "        self.prediction_temp_data = self.prediction_temp_data.rename(columns={\"time\": \"dt\",\n",
    "                                                                              \"temperature (F)\": \"tempF\"})\n",
    "        \n",
    "        self.prediction_meter_data = self.prediction_meter_data.set_index(\"start\")\n",
    "        self.prediction_temp_data = self.prediction_temp_data.set_index(\"dt\")\n",
    "        \n",
    "        prediction_meter_path = getcwd() + \"/{}_\".format(self.pod_id ) + \"prediction_meter\" \n",
    "        prediction_temp_path = getcwd() + \"/{}_\".format(self.pod_id ) + \"prediction_temp\" \n",
    "        \n",
    "        self.prediction_meter_data = self.prediction_meter_data.to_csv(r'{}'.format(prediction_meter_path))\n",
    "        self.prediction_temp_data = self.prediction_temp_data.to_csv(r'{}'.format(prediction_temp_path))\n",
    "        \n",
    "        self.ee_prediction_meter = eemeter.meter_data_from_csv(prediction_meter_path)\n",
    "            \n",
    "        self.ee_prediction_temp = eemeter.temperature_data_from_csv(prediction_temp_path) \n",
    "        self.ee_prediction_temp = self.ee_prediction_temp.asfreq('H')\n",
    "        \n",
    "        return self.ee_prediction_meter, self.ee_prediction_temp\n",
    "    \n",
    "    \n",
    "    \n",
    "    def estimate_metered_savings(self): \n",
    "        design_matrix = eemeter.create_caltrack_billing_design_matrix(self.ee_baseline_meter, \n",
    "                                                                      self.ee_baseline_temp)\n",
    "        baseline_model = eemeter.fit_caltrack_usage_per_day_model(design_matrix)\n",
    "        \n",
    "        # Generating index for prediction \n",
    "        prediction_date_range = pd.date_range(start=self.prediction_start, \n",
    "                                              end=self.prediction_end, \n",
    "                                              freq='D')\n",
    "        \n",
    "        \n",
    "        self.metered_savings, self.error_bands = eemeter.metered_savings(baseline_model, \n",
    "                                                              self.ee_prediction_meter,\n",
    "                                                              self.ee_prediction_temp)\n",
    "        \n",
    "        return self.metered_savings \n",
    "        \n",
    "    \n",
    "    \n",
    "    def establish_connection_to_spreadsheets(self, \n",
    "                                            spreadsheet_id, \n",
    "                                            range_name,\n",
    "                                            connection_type, \n",
    "                                            body=None): \n",
    "        \n",
    "        SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "        \n",
    "        SPREADSHEET_ID = spreadsheet_id \n",
    "        RANGE_NAME = range_name\n",
    "        \n",
    "        # This is where we make a batch get request \n",
    "        creds = None\n",
    "\n",
    "        if path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        # If there are no (valid) credentials available, let the user log in.\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    'credentials.json', SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            # Save the credentials for the next run\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        service = build('sheets', 'v4', credentials=creds)\n",
    "        \n",
    "        \n",
    "        sheet = service.spreadsheets()\n",
    "        \n",
    "        if connection_type == \"read\": \n",
    "            result = sheet.values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                                        range=RANGE_NAME).execute()\n",
    "        if connection_type == \"write\":\n",
    "            \n",
    "            result = service.spreadsheets().values().update(spreadsheetId=spreadsheet_id, \n",
    "                                                        range=range_name,\n",
    "                                                        valueInputOption=\"RAW\", \n",
    "                                                        body=body).execute()\n",
    "        print('{0} cells updated.'.format(result.get('updatedCells')))\n",
    "        \n",
    "        \n",
    "        return result\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    def update_project_metadata(self, \n",
    "                                spreadsheet_id, \n",
    "                                range_name): \n",
    "        '''\n",
    "        Goes into the Google Sheets where the project metadata is stored \n",
    "        and pulls the new metadata. \n",
    "        '''\n",
    "            \n",
    "        result = self.establish_connection_to_spreadsheets(spreadsheet_id,\n",
    "                                                            range_name, \n",
    "                                                           'read')\n",
    "        \n",
    "        raw_metadata = result.get('values', [])\n",
    "        \n",
    "        self.metadata = pd.DataFrame(raw_metadata[1:])\n",
    "        self.metadata.columns = raw_metadata[0]\n",
    "    \n",
    "        \n",
    "        return self.metadata\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportBuilder(ProjectEvaluator): \n",
    "    def __init__(self, files_path): \n",
    "        self.report = pd.DataFrame()\n",
    "        self.savings_breakdown = dict()\n",
    "        self.files_path = files_path \n",
    "        \n",
    "    def build(self): \n",
    "        case_id = []\n",
    "        reported_usage = [] \n",
    "        counterfactual_usage = [] \n",
    "        metered_savings = []\n",
    "\n",
    "        \n",
    "        for bill in glob.glob(self.files_path): \n",
    "            project_eval = ProjectEvaluator(bill)\n",
    "            project_eval.prepare_data()\n",
    "            project_eval.create_baseline_data()\n",
    "            project_eval.create_prediction_data()\n",
    "            project_eval.estimate_metered_savings()\n",
    "            \n",
    "            \n",
    "            case_id.append(project_eval.pod_id)\n",
    "            reported_usage.append(project_eval.metered_savings[\"reporting_observed\"].sum())\n",
    "            counterfactual_usage.append(project_eval.metered_savings[\"counterfactual_usage\"].sum())\n",
    "            metered_savings.append(project_eval.metered_savings[\"metered_savings\"].sum())\n",
    "            \n",
    "            \n",
    "            self.savings_breakdown[project_eval.pod_id] = project_eval.metered_savings\n",
    "            \n",
    "\n",
    "            \n",
    "        self.report[\"Case_ID\"] = case_id\n",
    "        self.report[\"Reported_Usage\"] = reported_usage\n",
    "        self.report[\"Counterfactual_Usage\"] = counterfactual_usage\n",
    "        self.report[\"Metered_Savings\"] = metered_savings\n",
    "        \n",
    "        \n",
    "        return self.report, self.savings_breakdown\n",
    "            \n",
    "    def export_to_spreadsheets(self, \n",
    "                               spreadsheet_id,\n",
    "                               range_name):\n",
    "        \n",
    "\n",
    "        # Read all existing data to ensure it doesn't get overwritten. \n",
    "        result = self.establish_connection_to_spreadsheets(spreadsheet_id,\n",
    "                                                           range_name,\n",
    "                                                           'read')\n",
    "        raw_project_data = result.get('values', [])\n",
    "\n",
    "    \n",
    "        # Recreate data as a dataframe so it is readable/modifiable. \n",
    "        project_data = pd.DataFrame(columns=raw_project_data[0])\n",
    "        data_by_cols = np.array(raw_project_data[1:]).T.tolist()\n",
    "\n",
    "        for i in range(len(raw_project_data[1])):\n",
    "            project_data[project_data.columns[i]] = data_by_cols[i]\n",
    "        \n",
    "        \n",
    "        # Update the prev. dataframe with the values from the report.  \n",
    "        project_data[\"Reported_Usage\"] = self.report[\"Reported_Usage\"]\n",
    "        project_data[\"Counterfactual_Usage\"] = self.report[\"Counterfactual_Usage\"]\n",
    "        project_data[\"Metered_Savings\"] = self.report[\"Metered_Savings\"]\n",
    "        \n",
    "        # Turn this updated df into the right format to export to sheets \n",
    "        values = []\n",
    "        values.append(list(project_data.columns))\n",
    "\n",
    "        for row in project_data.index:\n",
    "            values.append(list(project_data.loc[row]))\n",
    "            \n",
    "        \n",
    "        body = {\n",
    "            'values': values \n",
    "            }\n",
    "        \n",
    "        # Export to sheets. \n",
    "        updated_df = self.establish_connection_to_spreadsheets(spreadsheet_id,\n",
    "                                                               range_name, \n",
    "                                                               'write', \n",
    "                                                               body)                      \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None cells updated.\n",
      "creating design matrix for PoD IDN01000006827174\n",
      "creating baseline model for PoD IDN01000006827174\n",
      "creating design matrix for PoD IDN01000011073251\n",
      "creating baseline model for PoD IDN01000011073251\n",
      "creating design matrix for PoD IDN01000003628567\n",
      "creating baseline model for PoD IDN01000003628567\n",
      "None cells updated.\n",
      "32 cells updated.\n"
     ]
    }
   ],
   "source": [
    "project_data_sheet_id = '16Vc8jTaFnDeaqqefoM62xu2zaUHvad9Fm27BueYieOw'\n",
    "range_name = 'Main'\n",
    "\n",
    "reports = ReportBuilder('Electricity/*?.csv')\n",
    "reports.update_project_metadata(project_data_sheet_id, range_name)\n",
    "summary, breakdown = reports.build()\n",
    "reports.export_to_spreadsheets(project_data_sheet_id, range_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
